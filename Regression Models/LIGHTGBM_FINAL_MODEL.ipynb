{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr88kxDbRD52",
        "outputId": "00685d14-c4ed-414d-90a7-98f95fcdb450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "⚡ LIGHTGBM REGRESSOR — FINAL, FAST, AND STABLE\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time, json, joblib, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "except ImportError:\n",
        "    raise ImportError(\"Please install lightgbm: pip install lightgbm\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"⚡ LIGHTGBM REGRESSOR — FINAL, FAST, AND STABLE\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load dataset safely, skipping bad lines if any\n",
        "try:\n",
        "    df = pd.read_csv(\"crop_yield.csv\")\n",
        "except pd.errors.ParserError:\n",
        "    df = pd.read_csv(\"crop_yield.csv\", on_bad_lines='skip', engine='python')\n",
        "print(f\"Dataset loaded: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
        "\n",
        "# 2. Detect target column automatically\n",
        "possible_targets = [\"Yield\", \"Yield_tons_per_hectare\", \"yield\", \"Crop_Yield\", \"Production\"]\n",
        "target_col = next((c for c in possible_targets if c in df.columns), None)\n",
        "if target_col is None:\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if numeric_cols:\n",
        "        target_col = numeric_cols[-1]\n",
        "        print(f\"No standard target found — using '{target_col}'\")\n",
        "    else:\n",
        "        raise ValueError(\"No numeric target column found! Please specify target column.\")\n",
        "else:\n",
        "    print(f\"Target detected: {target_col}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh0xV7quYLVK",
        "outputId": "f1771f64-0e57-40b1-93b1-ce5786079448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: 303,102 rows × 10 columns\n",
            "Target detected: Yield_tons_per_hectare\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Encode categorical columns\n",
        "categoricals = df.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n",
        "if target_col in categoricals: categoricals.remove(target_col)\n",
        "encoders = {}\n",
        "for col in categoricals:\n",
        "    le = LabelEncoder()\n",
        "    df[col + \"_encoded\"] = le.fit_transform(df[col].astype(str))\n",
        "    encoders[col] = le\n",
        "df.drop(columns=categoricals, inplace=True)\n",
        "print(f\"Categorical columns encoded: {len(encoders)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-df_4WyYXmk",
        "outputId": "026c46ef-30f3-4a87-f338-1ba4a9cc3b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical columns encoded: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Prepare features and target\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "print(f\"Prepared {X.shape[1]} features with target range [{y.min():.2f}, {y.max():.2f}]\")\n",
        "\n",
        "# 5. Split data (80-20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "print(f\"Train: {len(X_train):,} | Test: {len(X_test):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKJJX--JYa4u",
        "outputId": "9b804505-4b2a-4267-ebce-aedf50ac7fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared 9 features with target range [-0.84, 9.73]\n",
            "Train: 242,481 | Test: 60,621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Detect device: GPU if available else CPU\n",
        "use_gpu = True\n",
        "try:\n",
        "    if use_gpu:\n",
        "        test = lgb.LGBMRegressor(device_type=\"gpu\", n_estimators=5, verbosity=-1)\n",
        "        test.fit(X_train[:50], y_train[:50])\n",
        "        device = \"gpu\"\n",
        "        print(\"GPU detected and enabled\")\n",
        "    else:\n",
        "        raise Exception(\"CPU mode forced\")\n",
        "except:\n",
        "    device = \"cpu\"\n",
        "    print(\"Using CPU mode\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a646YAqYd3P",
        "outputId": "c3b93016-32c9-4d89-8220-b129fabe473a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU detected and enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = lgb.LGBMRegressor(random_state=42, device=device)\n",
        "\n",
        "# Reduced parameter grid for faster tuning\n",
        "param_grid = {\n",
        "    \"num_leaves\": [31, 63],              # fewer options\n",
        "    \"learning_rate\": [0.05, 0.1],        # narrowed range\n",
        "    \"n_estimators\": [100, 200],           # fewer trees\n",
        "    \"max_depth\": [7, 10],                 # smaller depths\n",
        "    \"feature_fraction\": [0.8, 1.0],\n",
        "    \"bagging_fraction\": [0.8, 1.0],\n",
        "    \"lambda_l1\": [0],\n",
        "    \"lambda_l2\": [0, 1]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    model, param_distributions=param_grid,\n",
        "    n_iter=8,                            # fewer iterations\n",
        "    cv=2,                               # fewer CV folds\n",
        "    scoring=\"r2\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Enable early stopping to save time during fit\n",
        "fit_params = {\n",
        "    'eval_set': [(X_train, y_train)],\n",
        "    'eval_metric': 'rmse',\n",
        "    'callbacks': [lgb.early_stopping(30, verbose=False)] # Correct way to pass early stopping\n",
        "}\n",
        "\n",
        "t0 = time.time()\n",
        "search.fit(X_train, y_train, **fit_params)\n",
        "tune_time = time.time() - t0\n",
        "\n",
        "print(f\"✅ Tuning completed in {tune_time:.1f} seconds | Best R²: {search.best_score_:.4f}\")\n",
        "print(f\"Best params: {search.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGFKQzmtcrf0",
        "outputId": "8f07879c-46ec-4447-c70e-0d2404a34aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tuning completed in 86.5 seconds | Best R²: 0.9126\n",
            "Best params: {'num_leaves': 31, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05, 'lambda_l2': 0, 'lambda_l1': 0, 'feature_fraction': 1.0, 'bagging_fraction': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ba4617a",
        "outputId": "b8008d8d-058c-45ee-e8ba-d94e94518ac5"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Re-load dataset for pipeline construction (to get original columns)\n",
        "df_pipeline = pd.read_csv(\"crop_yield.csv\")\n",
        "\n",
        "# Ensure target column is identified correctly in this fresh df\n",
        "possible_targets = [\"Yield\", \"Yield_tons_per_hectare\", \"yield\", \"Crop_Yield\", \"Production\"]\n",
        "target_col_pipeline = next((c for c in possible_targets if c in df_pipeline.columns), None)\n",
        "if target_col_pipeline is None:\n",
        "    numeric_cols_pipeline = df_pipeline.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if numeric_cols_pipeline:\n",
        "        target_col_pipeline = numeric_cols_pipeline[-1]\n",
        "    else:\n",
        "        raise ValueError(\"No numeric target column found! Please specify target column.\")\n",
        "else:\n",
        "    print(f\"Target detected for pipeline: {target_col_pipeline}\")\n",
        "\n",
        "# Define features for the pipeline based on the original dataframe\n",
        "all_features_pipeline = [col for col in df_pipeline.columns if col != target_col_pipeline]\n",
        "numeric_features_pipeline = df_pipeline[all_features_pipeline].select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features_pipeline = df_pipeline[all_features_pipeline].select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "\n",
        "X_pipeline = df_pipeline.drop(columns=[target_col_pipeline])\n",
        "y_pipeline = df_pipeline[target_col_pipeline]\n",
        "\n",
        "# Split data for pipeline (using original features)\n",
        "X_train_pipeline, X_test_pipeline, y_train_pipeline, y_test_pipeline = train_test_split(\n",
        "    X_pipeline, y_pipeline, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"Pipeline features (numeric): {numeric_features_pipeline}\")\n",
        "print(f\"Pipeline features (categorical): {categorical_features_pipeline}\")\n",
        "print(f\"Train set for pipeline: {len(X_train_pipeline):,} | Test set for pipeline: {len(X_test_pipeline):,}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target detected for pipeline: Yield_tons_per_hectare\n",
            "Pipeline features (numeric): ['Rainfall_mm', 'Temperature_Celsius', 'Days_to_Harvest']\n",
            "Pipeline features (categorical): ['Region', 'Soil_Type', 'Crop', 'Fertilizer_Used', 'Irrigation_Used', 'Weather_Condition']\n",
            "Train set for pipeline: 269,420 | Test set for pipeline: 67,356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d36352fa"
      },
      "source": [
        "Now, we will define the `ColumnTransformer` for preprocessing and integrate it with the LightGBM Regressor into a `Pipeline`. We'll use the best parameters found during the previous `RandomizedSearchCV`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "978d6b8e",
        "outputId": "51e0fbc4-abac-430b-ba71-87e56e6fe30a"
      },
      "source": [
        "# Create the preprocessing pipeline using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features_pipeline),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_pipeline)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns if any, or 'drop' if you want to explicitly exclude them\n",
        ")\n",
        "\n",
        "# Get best parameters from previous RandomizedSearchCV\n",
        "best_lgbm_params = search.best_params_\n",
        "\n",
        "# Create the full pipeline with preprocessing and LightGBM model\n",
        "pipeline_lgbm = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', lgb.LGBMRegressor(**best_lgbm_params))\n",
        "])\n",
        "\n",
        "print(\"Fitting the new LightGBM pipeline with ColumnTransformer...\")\n",
        "# Fit the entire pipeline on the original (unscaled, unencoded) training data\n",
        "# Note: eval_set and callbacks can be passed to the fit method of the pipeline\n",
        "# if the regressor step supports them and can handle transformed data.\n",
        "pipeline_lgbm.fit(X_train_pipeline, y_train_pipeline)\n",
        "print(\"Pipeline fitting complete.\")\n",
        "\n",
        "# Evaluate the new pipeline\n",
        "y_pred_pipeline = pipeline_lgbm.predict(X_test_pipeline)\n",
        "\n",
        "train_r2_pipeline = r2_score(y_train_pipeline, pipeline_lgbm.predict(X_train_pipeline))\n",
        "test_r2_pipeline = r2_score(y_test_pipeline, y_pred_pipeline)\n",
        "mae_pipeline = mean_absolute_error(y_test_pipeline, y_pred_pipeline)\n",
        "rmse_pipeline = np.sqrt(mean_squared_error(y_test_pipeline, y_pred_pipeline))\n",
        "mape_pipeline = mean_absolute_percentage_error(y_test_pipeline, y_pred_pipeline) * 100\n",
        "gap_pipeline = train_r2_pipeline - test_r2_pipeline\n",
        "\n",
        "print(\"\\n======================================================================\")\n",
        "print(\"FINAL LIGHTGBM PIPELINE RESULTS\")\n",
        "print(\"======================================================================\")\n",
        "print(f\"Train R² (Pipeline): {train_r2_pipeline:.4f}\")\n",
        "print(f\"Test  R² (Pipeline): {test_r2_pipeline:.4f} ⭐\")\n",
        "print(f\"MAE (Pipeline): {mae_pipeline:.4f}\")\n",
        "print(f\"RMSE (Pipeline): {rmse_pipeline:.4f}\")\n",
        "print(f\"MAPE (Pipeline): {mape_pipeline:.2f}%\")\n",
        "print(f\"Overfit Gap (Pipeline): {gap_pipeline:.4f} → {'Excellent' if gap_pipeline < 0.03 else 'Good' if gap_pipeline < 0.06 else 'Moderate'}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting the new LightGBM pipeline with ColumnTransformer...\n",
            "Pipeline fitting complete.\n",
            "\n",
            "======================================================================\n",
            "FINAL LIGHTGBM PIPELINE RESULTS\n",
            "======================================================================\n",
            "Train R² (Pipeline): 0.9140\n",
            "Test  R² (Pipeline): 0.9123 ⭐\n",
            "MAE (Pipeline): 0.4004\n",
            "RMSE (Pipeline): 0.5023\n",
            "MAPE (Pipeline): 13.03%\n",
            "Overfit Gap (Pipeline): 0.0018 → Excellent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96dbbc26"
      },
      "source": [
        "Finally, we save the complete `pipeline_lgbm` object to a `.pkl` file. This file will contain all preprocessing steps and the trained LightGBM model, ready for future predictions on raw, unengineered input data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6ff8409d",
        "outputId": "07ece07b-56e3-4c24-a544-2b8e901431ef"
      },
      "source": [
        "# Save the complete pipeline to a .pkl file\n",
        "joblib.dump(pipeline_lgbm, 'lightgbm_full_prediction_pipeline.pkl')\n",
        "print(\"\\nFull LightGBM prediction pipeline saved to 'lightgbm_full_prediction_pipeline.pkl'\")\n",
        "\n",
        "# Uncomment below for download in Google Colab:\n",
        "from google.colab import files\n",
        "files.download('lightgbm_full_prediction_pipeline.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Full LightGBM prediction pipeline saved to 'lightgbm_full_prediction_pipeline.pkl'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b7aa8452-8719-4415-98db-af8b27e4c27c\", \"lightgbm_full_prediction_pipeline.pkl\", 622035)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Final training with early stopping\n",
        "final_model = search.best_estimator_\n",
        "t1 = time.time()\n",
        "final_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    callbacks=[lgb.early_stopping(25, verbose=False)]\n",
        ")\n",
        "train_time = time.time() - t1\n",
        "print(f\"Training completed in {train_time:.2f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLv7U1tvYkyp",
        "outputId": "3ec50918-2e20-424f-b3d4-5c524ecf7ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 3.06s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Evaluation\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Filter out NaN values from y_test and corresponding y_pred\n",
        "non_nan_indices = y_test.notna()\n",
        "y_test_filtered = y_test[non_nan_indices]\n",
        "y_pred_filtered = y_pred[non_nan_indices]\n",
        "\n",
        "train_r2 = r2_score(y_train, final_model.predict(X_train))\n",
        "test_r2 = r2_score(y_test_filtered, y_pred_filtered)\n",
        "mae = mean_absolute_error(y_test_filtered, y_pred_filtered)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_filtered, y_pred_filtered))\n",
        "mape = mean_absolute_percentage_error(y_test_filtered, y_pred_filtered)*100\n",
        "gap = train_r2 - test_r2\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FINAL LIGHTGBM RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Train R²: {train_r2:.4f}\")\n",
        "print(f\"Test  R²: {test_r2:.4f} ⭐\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")\n",
        "print(f\"Overfit Gap: {gap:.4f} → {'Excellent' if gap < 0.03 else 'Good' if gap < 0.06 else 'Moderate'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Wv249sYnyC",
        "outputId": "75a4cb3e-b642-4a8d-f2d9-a538403eb4a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FINAL LIGHTGBM RESULTS\n",
            "======================================================================\n",
            "Train R²: 0.9138\n",
            "Test  R²: 0.9125 ⭐\n",
            "MAE: 0.4003\n",
            "RMSE: 0.5023\n",
            "MAPE: 13.18%\n",
            "Overfit Gap: 0.0014 → Excellent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance\n",
        "feat_imp = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Importance\": final_model.feature_importances_\n",
        "}).sort_values(\"Importance\", ascending=False)\n",
        "feat_imp.to_csv(\"lightgbm_feature_importance.csv\", index=False)\n",
        "print(\"Feature importance saved to lightgbm_feature_importance.csv\")\n",
        "print(\"Top 5 features:\")\n",
        "for i, (f, v) in enumerate(feat_imp.head(5).values, 1):\n",
        "    print(f\"{i}. {f:<25} {v:.0f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNUxvj2-ZRhV",
        "outputId": "200d636d-520e-4ba6-a3fd-4bfe3a665881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importance saved to lightgbm_feature_importance.csv\n",
            "Top 5 features:\n",
            "1. Rainfall_mm               1510\n",
            "2. Temperature_Celsius       1283\n",
            "3. Irrigation_Used_encoded   643\n",
            "4. Days_to_Harvest           370\n",
            "5. Fertilizer_Used_encoded   331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_components = {\n",
        "    \"model\": final_model,\n",
        "    \"encoders\": encoders,\n",
        "    \"feature_importance\": feat_imp\n",
        "}\n",
        "joblib.dump(pipeline_components, \"lightgbm_full_pipeline.pkl\")\n",
        "print(\"Full pipeline (model, encoders, feature importance) saved to lightgbm_full_pipeline.pkl\")\n",
        "\n",
        "# Research summary\n",
        "summary = {\n",
        "    \"Model\": \"LightGBM Regressor\",\n",
        "    \"Device\": device,\n",
        "    \"Train_R2\": train_r2,\n",
        "    \"Test_R2\": test_r2,\n",
        "    \"MAE\": mae,\n",
        "    \"RMSE\": rmse,\n",
        "    \"MAPE\": mape,\n",
        "    \"Gap\": gap,\n",
        "    \"Best_Params\": search.best_params_,\n",
        "    \"Train_Time_s\": round(train_time, 2),\n",
        "    \"Tune_Time_s\": round(tune_time, 2),\n",
        "    \"Total_Time_min\": round((train_time + tune_time) / 60, 2)\n",
        "}\n",
        "import json\n",
        "json.dump(summary, open(\"lightgbm_summary.json\", \"w\"), indent=4)\n",
        "print(\"Summary saved to lightgbm_summary.json\")\n",
        "\n",
        "#Uncomment below for download in Google Colab:\n",
        "from google.colab import files\n",
        "files.download('lightgbm_full_pipeline.pkl')\n",
        "# files.download('lightgbm_summary.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "SYui-6enZVpI",
        "outputId": "52445b80-5fea-46f2-96ce-394d10234f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full pipeline (model, encoders, feature importance) saved to lightgbm_full_pipeline.pkl\n",
            "Summary saved to lightgbm_summary.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_158e42d8-e391-400a-9e95-4b079c056854\", \"lightgbm_full_pipeline.pkl\", 463639)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}